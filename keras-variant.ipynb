{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6e29d7-0fb5-4cbe-9a14-ae5e349969d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tokenwiser.pipeline import make_partial_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e7a113-324b-4ece-a16e-5c9044d9bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone (/home/vincent/.cache/huggingface/datasets/silicone/dyda_da/1.0.0/af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('silicone', 'dyda_da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0993c0-a24b-437b-a267-f7fd12633621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say , jim , how about going for a few beers af...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know that is tempting but is really not go...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do you mean ? it will help us to relax .</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you really think so ? i don't . it will jus...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i guess you are right.but what shall we do ? i...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>oh , it must be very precious . is it breakable ?</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>no , if you take some care when you use them .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>how much is it ?</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>two thousand .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>oh , it is beyond my purse .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95239 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  split\n",
       "0     say , jim , how about going for a few beers af...      1  train\n",
       "1     you know that is tempting but is really not go...      0  train\n",
       "2         what do you mean ? it will help us to relax .      3  train\n",
       "3     do you really think so ? i don't . it will jus...      3  train\n",
       "4     i guess you are right.but what shall we do ? i...      3  train\n",
       "...                                                 ...    ...    ...\n",
       "8064  oh , it must be very precious . is it breakable ?      3  valid\n",
       "8065     no , if you take some care when you use them .      2  valid\n",
       "8066                                   how much is it ?      3  valid\n",
       "8067                                     two thousand .      2  valid\n",
       "8068                       oh , it is beyond my purse .      2  valid\n",
       "\n",
       "[95239 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.concat([\n",
    "    ds['train'].to_pandas()[['Utterance', 'Label']].assign(split=\"train\"),\n",
    "    ds['validation'].to_pandas()[['Utterance', 'Label']].assign(split=\"valid\")\n",
    "]).rename(columns={'Utterance': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9a1fc56-ee02-4687-a0d8-4c2e0c8e88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset:\n",
    "    def __init__(self, path, text_col='text', label_col='label'):\n",
    "        dataf = pd.read_csv(path)\n",
    "        self.train = dataf.loc[lambda d: d['split'] == 'train'].reset_index()\n",
    "        self.valid = dataf.loc[lambda d: d['split'] == 'valid'].reset_index()\n",
    "        self.labels = list(dataf[label_col].unique())\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "        self.name = path\n",
    "    \n",
    "    def batch(self, n):\n",
    "        indices = np.random.randint(len(self.train), size=n)\n",
    "        subset = self.train.iloc[indices]\n",
    "        return subset[self.text_col], subset[self.label_col]\n",
    "    \n",
    "    def full(self, split=\"train\"):\n",
    "        subset = self.train if split == \"train\" else self.valid\n",
    "        return subset[self.text_col], subset[self.label_col]\n",
    "    \n",
    "\n",
    "class Batcher:\n",
    "    def __init__(self, dataset, tokeniser):\n",
    "        self.dataset = dataset\n",
    "        self.tokeniser = tokeniser\n",
    "        label_arr = np.array(self.dataset.labels).reshape(-1, 1)\n",
    "        self.label_enc = OneHotEncoder(sparse=False).fit(label_arr)\n",
    "    \n",
    "    def batch(self, n):\n",
    "        text, labs = self.dataset.batch(n=n)\n",
    "        label_arr = np.array(labs).reshape(-1, 1)\n",
    "        return self.tokeniser.transform(text), self.label_enc.transform(label_arr)\n",
    "    \n",
    "    def full(self, split=\"train\"):\n",
    "        text, labs = self.dataset.full(split=split)\n",
    "        label_arr = np.array(labs).reshape(-1, 1)\n",
    "        return self.tokeniser.transform(text), self.label_enc.transform(label_arr)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.tokeniser.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b32eb4d-9a61-458e-bfcb-b85fdefb100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = 20_000\n",
    "\n",
    "tok = make_partial_union(\n",
    "    HashingVectorizer(n_features=n_feat), \n",
    "    HashingVectorizer(n_features=n_feat, ngram_range=(2, 2))\n",
    ")\n",
    "\n",
    "batcher = Batcher(dataset=ClassificationDataset(\"data/silicone-dyda_da.csv\"), tokeniser=tok)\n",
    "# batcher.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b49d1266-68f3-4efa-93cc-32efb39cb5d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, name='silicone', subset='dyda_da', split='train', n_feat=20_000):\n",
    "        self.dataset = load_dataset(name, subset)\n",
    "        if isinstance(self.dataset, DatasetDict):\n",
    "            self.dataset = self.dataset[split]\n",
    "        self.labels = list(set(i['Label'] for i in self.dataset))\n",
    "        self.name = f\"{name}-{subset}-{split}\"\n",
    "        self.tfm = make_partial_union(\n",
    "            HashingVectorizer(n_features=n_feat), \n",
    "            HashingVectorizer(n_features=n_feat, ngram_range=(2, 2))\n",
    "        )\n",
    "        self.label_enc = OneHotEncoder(sparse=False).fit(np.array(self.labels).reshape(-1, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        return item['Utterance'], item['Label']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<TextDataset {self.name}>\"\n",
    "    \n",
    "    def batch(self, n):\n",
    "        \"\"\"Samples a random batch of `n` datapoints.\"\"\"\n",
    "        indices = np.random.randint(len(self), size=n)\n",
    "        texts, labels = zip(*[self[int(i)] for i in indices])\n",
    "        X = self.tfm.transform(texts)\n",
    "        y = self.label_enc.transform(np.array(labels).reshape(-1, 1))\n",
    "        return X, y\n",
    "    \n",
    "    def full(self):\n",
    "        \"\"\"Returns the full set in matrix form.\"\"\"\n",
    "        texts, labels = zip(*[self[int(i)] for i in range(len(self))])\n",
    "        X = self.tfm.transform(texts)\n",
    "        y = self.label_enc.transform(np.array(labels).reshape(-1, 1))\n",
    "        return X, y\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        return self.tfm.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41537dc7-b317-4fd5-8415-9cec9422443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datasets = {d.name: {'dataset': Batcher(d, tokeniser=tok)} for d in [\n",
    "    ClassificationDataset(\"data/silicone-dyda_da.csv\"),\n",
    "    ClassificationDataset(\"data/silicone-dyda_e.csv\"), \n",
    "    ClassificationDataset(\"data/silicone-meld_e.csv\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456dbdd-71f5-42b1-9992-d066e926adb4",
   "metadata": {},
   "source": [
    "```python\n",
    "fuse = (\n",
    "    FUSE(tokeniser, n_tok_feat)\n",
    "      .add_task(name, subset)\n",
    "      .add_task(name, subset)\n",
    "      .add_task(name, subset)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c71c5cdf-4a1b-48fe-890f-64411faec3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data/silicone-dyda_da.csv': {'dataset': <__main__.Batcher at 0x7f337a9c34d0>},\n",
       " 'data/silicone-dyda_e.csv': {'dataset': <__main__.Batcher at 0x7f337a891150>},\n",
       " 'data/silicone-meld_e.csv': {'dataset': <__main__.Batcher at 0x7f3379ed0890>}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a8d689b-e542-48b8-9764-18c32d6181e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "X = tok.transform([\"hello\"])\n",
    "inputs = Input(shape=(X.shape[1],), sparse=True)\n",
    "emb1 = Dense(256, activation='relu')(inputs)\n",
    "emb2 = Dense(256, activation='relu')(emb1)\n",
    "\n",
    "for dataset in my_datasets.values():\n",
    "    X, y = dataset['dataset'].batch(8)\n",
    "    dataset['outputs'] = Dense(y.shape[1], activation='softmax')(emb2)\n",
    "    dataset['model'] = Model(inputs=inputs, outputs=dataset['outputs'])\n",
    "    dataset['model'].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b7884-eac3-4ae9-9557-3a9f0e9ccfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/silicone-dyda_da.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_22/dense_29/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_22/dense_29/embedding_lookup_sparse/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_22/dense_29/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 105ms/step - loss: 1.2836 - accuracy: 0.4541 - val_loss: 1.2667 - val_accuracy: 0.3884\n",
      "data/silicone-dyda_e.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_23/dense_29/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_23/dense_29/embedding_lookup_sparse/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_23/dense_29/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 101ms/step - loss: 1.2411 - accuracy: 0.7700 - val_loss: 0.5584 - val_accuracy: 0.8809\n",
      "data/silicone-meld_e.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_24/dense_29/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_24/dense_29/embedding_lookup_sparse/Reshape:0\", shape=(None, 256), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_24/dense_29/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 93ms/step - loss: 1.6221 - accuracy: 0.4468 - val_loss: 1.7128 - val_accuracy: 0.4238\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.3915 - accuracy: 0.5200 - val_loss: 1.1851 - val_accuracy: 0.5810\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.7262 - accuracy: 0.8198 - val_loss: 0.4761 - val_accuracy: 0.8809\n",
      "data/silicone-meld_e.csv\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.5293 - accuracy: 0.4639 - val_loss: 1.6040 - val_accuracy: 0.4238\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 1.0322 - accuracy: 0.6274 - val_loss: 1.0137 - val_accuracy: 0.5913\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.6311 - accuracy: 0.8223 - val_loss: 0.4422 - val_accuracy: 0.8809\n",
      "data/silicone-meld_e.csv\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 1.4104 - accuracy: 0.4873 - val_loss: 1.5575 - val_accuracy: 0.4310\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.8689 - accuracy: 0.6812 - val_loss: 0.9129 - val_accuracy: 0.6210\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.5562 - accuracy: 0.8394 - val_loss: 0.4125 - val_accuracy: 0.8845\n",
      "data/silicone-meld_e.csv\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 1.3415 - accuracy: 0.5054 - val_loss: 1.5240 - val_accuracy: 0.4463\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.7819 - accuracy: 0.7144 - val_loss: 0.8612 - val_accuracy: 0.6582\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.5020 - accuracy: 0.8501 - val_loss: 0.3959 - val_accuracy: 0.8919\n",
      "data/silicone-meld_e.csv\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.2216 - accuracy: 0.5708 - val_loss: 1.4887 - val_accuracy: 0.4463\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.7432 - accuracy: 0.7183 - val_loss: 0.8197 - val_accuracy: 0.6795\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.5312 - accuracy: 0.8423 - val_loss: 0.4127 - val_accuracy: 0.8909\n",
      "data/silicone-meld_e.csv\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 1.1130 - accuracy: 0.6191 - val_loss: 1.4709 - val_accuracy: 0.4509\n",
      "data/silicone-dyda_da.csv\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.7119 - accuracy: 0.7246 - val_loss: 0.7972 - val_accuracy: 0.6908\n",
      "data/silicone-dyda_e.csv\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.5039 - accuracy: 0.8438 - val_loss: 0.3935 - val_accuracy: 0.8945\n",
      "data/silicone-meld_e.csv\n",
      " 5/16 [========>.....................] - ETA: 0s - loss: 1.1027 - accuracy: 0.6203"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for dataset in my_datasets.keys():\n",
    "        X, y = my_datasets[dataset]['dataset'].batch(2048)\n",
    "        print(dataset)\n",
    "        valid_data = my_datasets[dataset]['dataset'].full(split=\"valid\")\n",
    "        my_datasets[dataset]['model'].fit(X, y, batch_size=128, validation_data=valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06f82120-21b7-4baa-af74-0cd9c972ba37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.276060</td>\n",
       "      <td>0.317364</td>\n",
       "      <td>0.135484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.276060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754460</td>\n",
       "      <td>0.858188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.317364</td>\n",
       "      <td>0.754460</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.135484</td>\n",
       "      <td>0.858188</td>\n",
       "      <td>0.808464</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000  0.276060  0.317364  0.135484\n",
       "1  0.276060  1.000000  0.754460  0.858188\n",
       "2  0.317364  0.754460  1.000000  0.808464\n",
       "3  0.135484  0.858188  0.808464  1.000000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model = Model(inputs=inputs, outputs=emb2)\n",
    "pd.DataFrame(emb_model.predict(tok.transform([\"bad\", \"good\", \"joy\", \"happy\"]))).T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56795308-1be0-4d08-9752-32dd13384a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
