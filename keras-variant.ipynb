{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6e29d7-0fb5-4cbe-9a14-ae5e349969d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tokenwiser.pipeline import make_partial_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e7a113-324b-4ece-a16e-5c9044d9bcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset silicone (/home/vincent/.cache/huggingface/datasets/silicone/dyda_da/1.0.0/af617406c94e3f78da85f7ea74ebfbd3f297a9665cb54adbae305b03bc4442a5)\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('silicone', 'dyda_da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0993c0-a24b-437b-a267-f7fd12633621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say , jim , how about going for a few beers af...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know that is tempting but is really not go...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what do you mean ? it will help us to relax .</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do you really think so ? i don't . it will jus...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i guess you are right.but what shall we do ? i...</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>oh , it must be very precious . is it breakable ?</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>no , if you take some care when you use them .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>how much is it ?</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>two thousand .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>oh , it is beyond my purse .</td>\n",
       "      <td>2</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95239 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  split\n",
       "0     say , jim , how about going for a few beers af...      1  train\n",
       "1     you know that is tempting but is really not go...      0  train\n",
       "2         what do you mean ? it will help us to relax .      3  train\n",
       "3     do you really think so ? i don't . it will jus...      3  train\n",
       "4     i guess you are right.but what shall we do ? i...      3  train\n",
       "...                                                 ...    ...    ...\n",
       "8064  oh , it must be very precious . is it breakable ?      3  valid\n",
       "8065     no , if you take some care when you use them .      2  valid\n",
       "8066                                   how much is it ?      3  valid\n",
       "8067                                     two thousand .      2  valid\n",
       "8068                       oh , it is beyond my purse .      2  valid\n",
       "\n",
       "[95239 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd.concat([\n",
    "    ds['train'].to_pandas()[['Utterance', 'Label']].assign(split=\"train\"),\n",
    "    ds['validation'].to_pandas()[['Utterance', 'Label']].assign(split=\"valid\")\n",
    "]).rename(columns={'Utterance': 'text', 'Label': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9a1fc56-ee02-4687-a0d8-4c2e0c8e88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset:\n",
    "    def __init__(self, path, text_col='text', label_col='label'):\n",
    "        dataf = pd.read_csv(path)\n",
    "        self.train = dataf.loc[lambda d: d['split'] == 'train'].reset_index()\n",
    "        self.valid = dataf.loc[lambda d: d['split'] == 'valid'].reset_index()\n",
    "        self.labels = list(dataf[label_col].unique())\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "        self.name = path\n",
    "    \n",
    "    def batch(self, n):\n",
    "        indices = np.random.randint(len(self.train), size=n)\n",
    "        subset = self.train.iloc[indices]\n",
    "        return subset[self.text_col], subset[self.label_col]\n",
    "    \n",
    "    def full(self, split=\"train\"):\n",
    "        subset = self.train if split == \"train\" else self.valid\n",
    "        return subset[self.text_col], subset[self.label_col]\n",
    "    \n",
    "\n",
    "class Batcher:\n",
    "    def __init__(self, dataset, tokeniser):\n",
    "        self.dataset = dataset\n",
    "        self.tokeniser = tokeniser\n",
    "        label_arr = np.array(self.dataset.labels).reshape(-1, 1)\n",
    "        self.label_enc = OneHotEncoder(sparse=False).fit(label_arr)\n",
    "    \n",
    "    def batch(self, n):\n",
    "        text, labs = self.dataset.batch(n=n)\n",
    "        label_arr = np.array(labs).reshape(-1, 1)\n",
    "        return self.tokeniser.transform(text), self.label_enc.transform(label_arr)\n",
    "    \n",
    "    def full(self, split=\"train\"):\n",
    "        text, labs = self.dataset.full(split=split)\n",
    "        label_arr = np.array(labs).reshape(-1, 1)\n",
    "        return self.tokeniser.transform(text), self.label_enc.transform(label_arr)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.tokeniser.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b32eb4d-9a61-458e-bfcb-b85fdefb100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = 20_000\n",
    "\n",
    "tok = make_partial_union(\n",
    "    HashingVectorizer(n_features=n_feat), \n",
    "    HashingVectorizer(n_features=n_feat, ngram_range=(2, 2))\n",
    ")\n",
    "\n",
    "batcher = Batcher(dataset=ClassificationDataset(\"data/silicone-dyda_da.csv\"), tokeniser=tok)\n",
    "# batcher.batch(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b49d1266-68f3-4efa-93cc-32efb39cb5d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, name='silicone', subset='dyda_da', split='train', n_feat=20_000):\n",
    "        self.dataset = load_dataset(name, subset)\n",
    "        if isinstance(self.dataset, DatasetDict):\n",
    "            self.dataset = self.dataset[split]\n",
    "        self.labels = list(set(i['Label'] for i in self.dataset))\n",
    "        self.name = f\"{name}-{subset}-{split}\"\n",
    "        self.tfm = make_partial_union(\n",
    "            HashingVectorizer(n_features=n_feat), \n",
    "            HashingVectorizer(n_features=n_feat, ngram_range=(2, 2))\n",
    "        )\n",
    "        self.label_enc = OneHotEncoder(sparse=False).fit(np.array(self.labels).reshape(-1, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        return item['Utterance'], item['Label']\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<TextDataset {self.name}>\"\n",
    "    \n",
    "    def batch(self, n):\n",
    "        \"\"\"Samples a random batch of `n` datapoints.\"\"\"\n",
    "        indices = np.random.randint(len(self), size=n)\n",
    "        texts, labels = zip(*[self[int(i)] for i in indices])\n",
    "        X = self.tfm.transform(texts)\n",
    "        y = self.label_enc.transform(np.array(labels).reshape(-1, 1))\n",
    "        return X, y\n",
    "    \n",
    "    def full(self):\n",
    "        \"\"\"Returns the full set in matrix form.\"\"\"\n",
    "        texts, labels = zip(*[self[int(i)] for i in range(len(self))])\n",
    "        X = self.tfm.transform(texts)\n",
    "        y = self.label_enc.transform(np.array(labels).reshape(-1, 1))\n",
    "        return X, y\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        return self.tfm.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41537dc7-b317-4fd5-8415-9cec9422443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_datasets = {d.name: {'dataset': Batcher(d, tokeniser=tok)} for d in [\n",
    "    ClassificationDataset(\"data/silicone-dyda_da.csv\"),\n",
    "    ClassificationDataset(\"data/silicone-dyda_e.csv\"), \n",
    "    ClassificationDataset(\"data/silicone-meld_e.csv\"),\n",
    "    ClassificationDataset(\"data/tweet_eval-emoji.csv\"),\n",
    "    ClassificationDataset(\"data/tweet_eval-emotion.csv\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456dbdd-71f5-42b1-9992-d066e926adb4",
   "metadata": {},
   "source": [
    "```python\n",
    "fuse = (\n",
    "    FUSE(tokeniser, n_tok_feat)\n",
    "      .add_task(name, subset)\n",
    "      .add_task(name, subset)\n",
    "      .add_task(name, subset)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c71c5cdf-4a1b-48fe-890f-64411faec3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data/silicone-dyda_da.csv': {'dataset': <__main__.Batcher at 0x7f3412b45750>},\n",
       " 'data/silicone-dyda_e.csv': {'dataset': <__main__.Batcher at 0x7f3413222a10>},\n",
       " 'data/silicone-meld_e.csv': {'dataset': <__main__.Batcher at 0x7f33781f9450>},\n",
       " 'data/tweet_eval-emoji.csv': {'dataset': <__main__.Batcher at 0x7f33781f9750>},\n",
       " 'data/tweet_eval-emotion.csv': {'dataset': <__main__.Batcher at 0x7f33d432bd90>}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a8d689b-e542-48b8-9764-18c32d6181e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "X = tok.transform([\"hello\"])\n",
    "inputs = Input(shape=(X.shape[1],), sparse=True)\n",
    "emb1 = Dense(256, activation='relu')(inputs)\n",
    "emb2 = Dense(256, activation='relu')(emb1)\n",
    "\n",
    "for dataset in my_datasets.values():\n",
    "    X, y = dataset['dataset'].batch(8)\n",
    "    dataset['outputs'] = Dense(y.shape[1], activation='softmax')(emb2)\n",
    "    dataset['model'] = Model(inputs=inputs, outputs=dataset['outputs'])\n",
    "    dataset['model'].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee0b7884-eac3-4ae9-9557-3a9f0e9ccfbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/silicone-dyda_da.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.7264 - accuracy: 0.7363 - val_loss: 0.7936 - val_accuracy: 0.6941\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.3759 - accuracy: 0.8740 - val_loss: 0.7986 - val_accuracy: 0.6962\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1839 - accuracy: 0.9556 - val_loss: 0.8557 - val_accuracy: 0.6931\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.0893 - accuracy: 0.9849 - val_loss: 0.9129 - val_accuracy: 0.6883\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0511 - accuracy: 0.9902 - val_loss: 0.9376 - val_accuracy: 0.6861\n",
      "data/silicone-dyda_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.5183 - accuracy: 0.8452 - val_loss: 0.3749 - val_accuracy: 0.8908\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.3269 - accuracy: 0.8877 - val_loss: 0.3752 - val_accuracy: 0.8895\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1839 - accuracy: 0.9399 - val_loss: 0.3930 - val_accuracy: 0.8840\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1039 - accuracy: 0.9658 - val_loss: 0.4128 - val_accuracy: 0.8831\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0644 - accuracy: 0.9839 - val_loss: 0.4406 - val_accuracy: 0.8783\n",
      "data/silicone-meld_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.9360 - accuracy: 0.6929 - val_loss: 1.5645 - val_accuracy: 0.4734\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.5276 - accuracy: 0.8467 - val_loss: 1.5788 - val_accuracy: 0.4662\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.3220 - accuracy: 0.9141 - val_loss: 1.6557 - val_accuracy: 0.4472\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.2132 - accuracy: 0.9463 - val_loss: 1.7395 - val_accuracy: 0.4599\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.1647 - accuracy: 0.9526 - val_loss: 1.8133 - val_accuracy: 0.4509\n",
      "data/tweet_eval-emoji.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.4100 - accuracy: 0.3022 - val_loss: 2.6239 - val_accuracy: 0.2510\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 1.6392 - accuracy: 0.5762 - val_loss: 2.5878 - val_accuracy: 0.2520\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.9194 - accuracy: 0.8350 - val_loss: 2.6308 - val_accuracy: 0.2492\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.4221 - accuracy: 0.9600 - val_loss: 2.7155 - val_accuracy: 0.2384\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.1806 - accuracy: 0.9907 - val_loss: 2.7831 - val_accuracy: 0.2380\n",
      "data/tweet_eval-emotion.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0813 - accuracy: 0.9795 - val_loss: 1.2083 - val_accuracy: 0.5882\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 1.2003 - val_accuracy: 0.5909\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0143 - accuracy: 0.9956 - val_loss: 1.2397 - val_accuracy: 0.5936\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 1.2542 - val_accuracy: 0.5829\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 1.2376 - val_accuracy: 0.5856\n",
      "data/silicone-dyda_da.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.8045 - accuracy: 0.7275 - val_loss: 0.9241 - val_accuracy: 0.6760\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.1964 - accuracy: 0.9429 - val_loss: 0.9344 - val_accuracy: 0.6765\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0764 - accuracy: 0.9849 - val_loss: 0.9673 - val_accuracy: 0.6727\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0451 - accuracy: 0.9888 - val_loss: 1.0068 - val_accuracy: 0.6718\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0332 - accuracy: 0.9912 - val_loss: 1.0331 - val_accuracy: 0.6723\n",
      "data/silicone-dyda_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.5711 - accuracy: 0.8359 - val_loss: 0.4512 - val_accuracy: 0.8600\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1935 - accuracy: 0.9385 - val_loss: 0.4204 - val_accuracy: 0.8735\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0874 - accuracy: 0.9780 - val_loss: 0.4380 - val_accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0520 - accuracy: 0.9863 - val_loss: 0.4612 - val_accuracy: 0.8776\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0379 - accuracy: 0.9912 - val_loss: 0.4886 - val_accuracy: 0.8810\n",
      "data/silicone-meld_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.8677 - accuracy: 0.7310 - val_loss: 1.8151 - val_accuracy: 0.4229\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.3394 - accuracy: 0.8960 - val_loss: 1.8205 - val_accuracy: 0.4337\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.2007 - accuracy: 0.9365 - val_loss: 1.8924 - val_accuracy: 0.4364\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 89ms/step - loss: 0.1546 - accuracy: 0.9512 - val_loss: 1.9893 - val_accuracy: 0.4409\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.1354 - accuracy: 0.9517 - val_loss: 2.0421 - val_accuracy: 0.4409\n",
      "data/tweet_eval-emoji.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 2.3341 - accuracy: 0.3535 - val_loss: 2.7754 - val_accuracy: 0.2394\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.7954 - accuracy: 0.8418 - val_loss: 2.7834 - val_accuracy: 0.2292\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.2614 - accuracy: 0.9736 - val_loss: 2.8644 - val_accuracy: 0.2186\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.1062 - accuracy: 0.9912 - val_loss: 2.9346 - val_accuracy: 0.2258\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.0613 - accuracy: 0.9922 - val_loss: 2.9906 - val_accuracy: 0.2242\n",
      "data/tweet_eval-emotion.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 92ms/step - loss: 0.0611 - accuracy: 0.9849 - val_loss: 1.3728 - val_accuracy: 0.5695\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 1.2337 - val_accuracy: 0.5829\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 1.2791 - val_accuracy: 0.5936\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.2797 - val_accuracy: 0.5829\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 1s 91ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 1.2867 - val_accuracy: 0.5936\n",
      "data/silicone-dyda_da.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.9366 - accuracy: 0.6958 - val_loss: 0.9729 - val_accuracy: 0.6562\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.2093 - accuracy: 0.9380 - val_loss: 0.9840 - val_accuracy: 0.6674\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0739 - accuracy: 0.9834 - val_loss: 1.0043 - val_accuracy: 0.6625\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0411 - accuracy: 0.9927 - val_loss: 1.0546 - val_accuracy: 0.6625\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.0272 - accuracy: 0.9951 - val_loss: 1.0882 - val_accuracy: 0.6627\n",
      "data/silicone-dyda_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 2s 97ms/step - loss: 0.5910 - accuracy: 0.8306 - val_loss: 0.4871 - val_accuracy: 0.8451\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.1449 - accuracy: 0.9556 - val_loss: 0.4416 - val_accuracy: 0.8680\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0645 - accuracy: 0.9834 - val_loss: 0.4594 - val_accuracy: 0.8824\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0344 - accuracy: 0.9937 - val_loss: 0.4722 - val_accuracy: 0.8679\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 0.4901 - val_accuracy: 0.8757\n",
      "data/silicone-meld_e.csv\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.8243 - accuracy: 0.7422 - val_loss: 1.9657 - val_accuracy: 0.3859\n",
      "Epoch 2/5\n",
      " 9/16 [===============>..............] - ETA: 0s - loss: 0.3003 - accuracy: 0.9062"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_427410/491874480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmy_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Development/fuse/venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for dataset in my_datasets.keys():\n",
    "        X, y = my_datasets[dataset]['dataset'].batch(2048)\n",
    "        print(dataset)\n",
    "        valid_data = my_datasets[dataset]['dataset'].full(split=\"valid\")\n",
    "        my_datasets[dataset]['model'].fit(X, y, batch_size=128, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "06f82120-21b7-4baa-af74-0cd9c972ba37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608054</td>\n",
       "      <td>0.482035</td>\n",
       "      <td>0.293303</td>\n",
       "      <td>0.231563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798869</td>\n",
       "      <td>0.687975</td>\n",
       "      <td>0.634797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.482035</td>\n",
       "      <td>0.798869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707324</td>\n",
       "      <td>0.822916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.293303</td>\n",
       "      <td>0.687975</td>\n",
       "      <td>0.707324</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231563</td>\n",
       "      <td>0.634797</td>\n",
       "      <td>0.822916</td>\n",
       "      <td>0.816903</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4\n",
       "0  1.000000  0.608054  0.482035  0.293303  0.231563\n",
       "1  0.608054  1.000000  0.798869  0.687975  0.634797\n",
       "2  0.482035  0.798869  1.000000  0.707324  0.822916\n",
       "3  0.293303  0.687975  0.707324  1.000000  0.816903\n",
       "4  0.231563  0.634797  0.822916  0.816903  1.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model = Model(inputs=inputs, outputs=emb2)\n",
    "pd.DataFrame(emb_model.predict(tok.transform([\"bad\", \"evil\", \"good\", \"joy\", \"happy\"]))).T.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56795308-1be0-4d08-9752-32dd13384a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
